From 590e7f4256345082ff863e134890a7e9f04639f4 Mon Sep 17 00:00:00 2001
From: Noah Huetter <noahhuetter@gmail.com>
Date: Mon, 10 Jan 2022 14:13:13 +0100
Subject: [sw/snitch] Add kNN to snBLAS

Signed-off-by: Noah Huetter <noahhuetter@gmail.com>
---
 sw/snBLAS/CMakeLists.txt          |   9 ++-
 sw/snBLAS/include/knn.h           |  27 +++++++++
 sw/snBLAS/include/knn_data.h      |  51 +++++++++++++++++
 sw/snBLAS/include/snblas.h        |  17 ++++++
 sw/snBLAS/scripts/gen_data_knn.py | 115 +++++++++++++++++++++++++++++++++++++
 sw/snBLAS/src/knn.c               | 116 ++++++++++++++++++++++++++++++++++++++
 6 files changed, 334 insertions(+), 1 deletion(-)
 create mode 100644 sw/vendor/snitch/sw/snBLAS/include/knn.h
 create mode 100644 sw/vendor/snitch/sw/snBLAS/include/knn_data.h
 create mode 100644 sw/vendor/snitch/sw/snBLAS/scripts/gen_data_knn.py
 create mode 100644 sw/vendor/snitch/sw/snBLAS/src/knn.c

diff --git a/sw/snBLAS/CMakeLists.txt b/sw/snBLAS/CMakeLists.txt
index 7e34c10..d020eb2 100644
--- a/sw/snBLAS/CMakeLists.txt
+++ b/sw/snBLAS/CMakeLists.txt
@@ -16,12 +16,19 @@ if (CMAKE_SOURCE_DIR STREQUAL CMAKE_CURRENT_SOURCE_DIR)
 
     # Build the runtime.
     add_subdirectory(../snRuntime snRuntime)
+else()
+    # Export package information to includer.
+    set(SNBLAS_DIR ${CMAKE_CURRENT_BINARY_DIR} PARENT_SCOPE)
+    set(SNBLAS_SRC_DIR ${CMAKE_CURRENT_SOURCE_DIR} PARENT_SCOPE)
+    set(SNBLAS_INCLUDE_DIRS
+        ${CMAKE_CURRENT_SOURCE_DIR}/include
+        PARENT_SCOPE)
 endif()
 
 include_directories(include)
 include_directories(${SNRUNTIME_INCLUDE_DIRS})
 
-add_snitch_library(snBLAS src/axpy.c)
+add_snitch_library(snBLAS src/axpy.c src/knn.c)
 
 # Tests
 enable_testing()
diff --git a/sw/snBLAS/include/knn.h b/sw/snBLAS/include/knn.h
new file mode 100644
index 0000000..6d2cd30
--- /dev/null
+++ b/sw/snBLAS/include/knn.h
@@ -0,0 +1,27 @@
+// Copyright 2021 ETH Zurich and University of Bologna.
+// Licensed under the Apache License, Version 2.0, see LICENSE for details.
+// SPDX-License-Identifier: Apache-2.0
+#pragma once
+
+#include <snblas.h>
+#include <stdint.h>
+
+struct knn_aux {
+  double dist;
+  uint32_t index;
+};
+
+/**
+ * @brief kNN algorithm. For each sample in `query`, calculate the euclidean distance to all data
+ * points in `data` and sort. Output is stored in `output`. `k` is currently ignored.
+ *
+ * @param K k in k-nn
+ * @param query_size number os samples to query
+ * @param data_size size of data set
+ * @param query elements to classify
+ * @param data input data set
+ * @param output sorted list with classifications
+ * @param ccfg compute configuration struct
+ */
+void knn_1d(uint32_t K, uint32_t query_size, uint32_t data_size, double *query, double *data,
+            struct knn_aux *output, computeConfig_t *ccfg);
diff --git a/sw/snBLAS/include/knn_data.h b/sw/snBLAS/include/knn_data.h
new file mode 100644
index 0000000..8bea149
--- /dev/null
+++ b/sw/snBLAS/include/knn_data.h
@@ -0,0 +1,51 @@
+// Copyright 2021 ETH Zurich and University of Bologna.
+// Licensed under the Apache License, Version 2.0, see LICENSE for details.
+// SPDX-License-Identifier: Apache-2.0
+#pragma once
+
+// Data for testing the knn library
+
+#include <stdint.h>
+
+static uint32_t knn_k3_N50_nrs8_input_size = 50;
+static uint32_t knn_k3_N50_nrs8_k_size = 3;
+static uint32_t knn_k3_N50_nrs8_nr_samples = 8;
+static double knn_k3_N50_nrs8_samples[8] = {
+    130.9866116770785, 226.25392339018188, 0.03592513012802889, 94.96266106366087,
+    46.09602530565521, 29.00355261687939,  58.504332393726436,  108.5406243642213};
+static double knn_k3_N50_nrs8_output_checksum[8] = {288.972, 314.1,   160.191, 251.28,
+                                                    204.165, 185.319, 216.729, 266.985};
+static uint32_t knn_k3_N100_nrs24_input_size = 100;
+static uint32_t knn_k3_N100_nrs24_k_size = 3;
+static uint32_t knn_k3_N100_nrs24_nr_samples = 24;
+static double knn_k3_N100_nrs24_samples[24] = {
+    261.973223354157,   452.50784678036376, 0.07185026025605779, 189.92532212732175,
+    92.19205061131042,  58.00710523375878,  117.00866478745287,  217.0812487284426,
+    249.24932731170688, 338.48467230090887, 263.3379939481498,   430.45489014924436,
+    128.43690328133926, 551.6333735407919,  17.20488604693722,   421.1876898940723,
+    262.15087684702917, 350.9689502296212,  88.19107482552586,   124.44735544312087,
+    503.02773804197216, 608.2619218669256,  196.89306871963637,  434.9170671634631};
+static double knn_k3_N100_nrs24_output_checksum[24] = {574.803,
+                                                       628.2,
+                                                       317.241,
+                                                       502.56,
+                                                       405.189,
+                                                       370.638,
+                                                       430.317,
+                                                       530.829,
+                                                       562.239,
+                                                       628.2,
+                                                       577.944,
+                                                       628.2,
+                                                       442.88100000000003,
+                                                       628.2,
+                                                       329.805,
+                                                       628.2,
+                                                       574.803,
+                                                       628.2,
+                                                       402.048,
+                                                       439.74,
+                                                       628.2,
+                                                       628.2,
+                                                       511.983,
+                                                       628.2};
diff --git a/sw/snBLAS/include/snblas.h b/sw/snBLAS/include/snblas.h
index 85c4f45..7bc8e92 100644
--- a/sw/snBLAS/include/snblas.h
+++ b/sw/snBLAS/include/snblas.h
@@ -3,4 +3,21 @@
 // SPDX-License-Identifier: Apache-2.0
 #pragma once
 
+#include <stdint.h>
+
+/**
+ * @brief Struct used to configure and profile kernels in snBLAS
+ *
+ */
+typedef struct computeConfig
+{
+    uint32_t cluster_num;
+    uint32_t compute_num;
+    uint32_t cluster_idx;
+    uint32_t cycle_start;
+    uint32_t cycle_end;
+    uint32_t *stmps;
+    uint32_t max_stmps;
+} computeConfig_t;
+
 double snblas_hello();
diff --git a/sw/snBLAS/scripts/gen_data_knn.py b/sw/snBLAS/scripts/gen_data_knn.py
new file mode 100644
index 0000000..aa2ac0c
--- /dev/null
+++ b/sw/snBLAS/scripts/gen_data_knn.py
@@ -0,0 +1,115 @@
+#!/usr/bin/env python3
+
+# Copied from:
+# https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761
+
+from collections import Counter
+import math
+import numpy as np
+
+
+def pseudo_rand_matrix(N, M, seed):
+    return np.arange(seed, seed+N*M, dtype=np.float64).reshape(M, N).transpose() * 3.141
+
+
+def knn(data, query, k, distance_fn, choice_fn):
+    neighbor_distances_and_indices = []
+    # print(data)
+    # 3. For each example in the data
+    for index, example in enumerate(data):
+        # 3.1 Calculate the distance between the query example and the current
+        # example from the data.
+        distance = distance_fn(example[:-1], query)
+
+        # 3.2 Add the distance and the index of the example to an ordered collection
+        neighbor_distances_and_indices.append((distance, index))
+
+    # 4. Sort the ordered collection of distances and indices from
+    # smallest to largest (in ascending order) by the distances
+    sorted_neighbor_distances_and_indices = sorted(neighbor_distances_and_indices)
+
+    # 5. Pick the first K entries from the sorted collection
+    k_nearest_distances_and_indices = sorted_neighbor_distances_and_indices[:k]
+
+    # 6. Get the labels of the selected K entries
+    k_nearest_labels = [data[i][1] for distance, i in k_nearest_distances_and_indices]
+    # print(f'k_nearest_distances_and_indices: {k_nearest_distances_and_indices}')
+    # print(f'k_nearest_labels: {k_nearest_labels}')
+    # print(f'choice_fn(k_nearest_labels): {choice_fn(k_nearest_labels)}')
+
+    # 7. If regression (choice_fn = mean), return the average of the K labels
+    # 8. If classification (choice_fn = mode), return the mode of the K labels
+    return k_nearest_distances_and_indices, choice_fn(k_nearest_labels)
+
+
+def mean(labels):
+    return sum(labels) / len(labels)
+
+
+def mode(labels):
+    return Counter(labels).most_common(1)[0][0]
+
+
+def euclidean_distance(point1, point2):
+    sum_squared_distance = 0
+    for i in range(len(point1)):
+        sum_squared_distance += math.pow(point1[i] - point2[i], 2)
+        # print(point1[i], point2[i])
+    # print("Result:", sum_squared_distance)
+    return sum_squared_distance
+
+
+def array_to_cstr(a):
+    out = '{'
+    if isinstance(a, np.ndarray):
+        a = a.flat
+    for el in a:
+        out += '{}, '.format(el)
+    out = out[:-2] + '}'
+    return out
+
+
+def emit(name, array, pfx=""):
+    if isinstance(array, int):
+        print(f'static uint32_t {pfx}{name} = {array};')
+        return
+    out = 'static '
+    if array.dtype == np.uint32:
+        out += 'uint32_t'
+    elif array.dtype == np.float64:
+        out += 'double'
+    else:
+        exit(-1)
+
+    out += f' {pfx}{name}[{array.size}] = {array_to_cstr(array)};'
+    print(out)
+
+
+N = 100
+k = 3
+nr_samples = 24
+
+name_prefix = f"knn_k{k}_N{N}_nrs{nr_samples}_"
+
+emit("input_size", N, pfx=name_prefix)
+emit("k_size", k, pfx=name_prefix)
+emit("nr_samples", nr_samples, pfx=name_prefix)
+
+reg_data = pseudo_rand_matrix(N, 2, 1)
+np.random.seed(seed=1)
+samples = np.random.uniform(0, reg_data[-1][-1], nr_samples)
+emit("samples", np.array(samples, dtype=np.float64), pfx=name_prefix)
+
+# print('samples')
+# print(samples)
+# print('reg_data')
+# print(reg_data)
+
+results = []
+for sample in samples:
+    reg_k_nearest_neighbors, reg_prediction = knn(
+        reg_data, [sample], k=k, distance_fn=euclidean_distance, choice_fn=mode
+    )
+    results.append(reg_prediction)
+
+emit("output_checksum", np.array(results, dtype=np.float64), pfx=name_prefix)
diff --git a/sw/snBLAS/src/knn.c b/sw/snBLAS/src/knn.c
new file mode 100644
index 0000000..57dc00b
--- /dev/null
+++ b/sw/snBLAS/src/knn.c
@@ -0,0 +1,116 @@
+// Copyright 2020 ETH Zurich and University of Bologna.
+// Licensed under the Apache License, Version 2.0, see LICENSE for details.
+// SPDX-License-Identifier: Apache-2.0
+#include "knn.h"
+#include "printf.h"
+#include <snblas.h>
+#include <snrt.h>
+#include <stdint.h>
+
+// Shell sort
+// Shamelessly copied from: https://www.programiz.com/dsa/shell-sort
+static void __attribute__((noinline)) shell_sort(struct knn_aux array[], int n) {
+  // Rearrange elements at each n/2, n/4, n/8, ... intervals
+  for (int interval = n / 2; interval > 0; interval /= 2) {
+    for (int i = interval; i < n; i += 1) {
+      struct knn_aux temp = array[i];
+      int j;
+      for (j = i; j >= interval && array[j - interval].dist > temp.dist; j -= interval) {
+        array[j] = array[j - interval];
+      }
+      array[j] = temp;
+    }
+  }
+}
+
+static void __attribute__((noinline))
+knn_seq(uint32_t K, uint32_t query_size, uint32_t data_size, double *query, double *data,
+        struct knn_aux *output, computeConfig_t *ccfg) {
+  uint32_t compute_id = snrt_cluster_compute_core_idx();
+
+  if (snrt_is_dm_core())
+    return;
+
+  snrt_ssr_loop_1d(SNRT_SSR_DM0, data_size, sizeof(double));
+  snrt_ssr_loop_1d(SNRT_SSR_DM1, data_size, sizeof(struct knn_aux));
+  snrt_ssr_read(SNRT_SSR_DM0, SNRT_SSR_1D, data);
+  snrt_ssr_write(SNRT_SSR_DM1, SNRT_SSR_1D, output);
+
+  snrt_ssr_enable();
+
+  register double tmp;
+  uint32_t dsize = data_size;
+  double qry = *query;
+
+  if (ccfg->cycle_start == 0)
+    ccfg->cycle_start = read_csr(mcycle);
+
+  // For each example in the data calculate the euclidean distance between the query example and the
+  // data first loop unrolled by 8
+  if (dsize > 8) {
+    asm volatile("frep.o %[n_frep], 16, 0, 0 \n"
+                 "fsub.d ft3, ft0, %[query] \n"
+                 "fsub.d ft4, ft0, %[query] \n"
+                 "fsub.d ft5, ft0, %[query] \n"
+                 "fsub.d ft6, ft0, %[query] \n"
+                 "fsub.d ft7, ft0, %[query] \n"
+                 "fsub.d ft8, ft0, %[query] \n"
+                 "fsub.d ft9, ft0, %[query] \n"
+                 "fsub.d ft10, ft0, %[query] \n"
+                 "fmul.d ft1, ft3, ft3 \n"
+                 "fmul.d ft1, ft4, ft4 \n"
+                 "fmul.d ft1, ft5, ft5 \n"
+                 "fmul.d ft1, ft6, ft6 \n"
+                 "fmul.d ft1, ft7, ft7 \n"
+                 "fmul.d ft1, ft8, ft8 \n"
+                 "fmul.d ft1, ft9, ft9 \n"
+                 "fmul.d ft1, ft10, ft10 \n"
+                 :
+                 : [ query ] "f"(qry), [ n_frep ] "r"(dsize / 8 - 1)
+                 : "ft0", "ft1", "ft3", "ft4", "ft5", "ft6", "ft7", "ft8", "ft9", "ft10", "memory");
+    dsize -= 8 * (dsize / 8);
+  }
+  // Reminder
+  if (dsize) {
+    asm volatile("frep.o %[n_frep], 2, 0, 0 \n"
+                 "fsub.d ft3, ft0, %[query] \n"
+                 "fmul.d ft1, ft3, ft3 \n"
+                 :
+                 : [ query ] "f"(qry), [ n_frep ] "r"(dsize - 1)
+                 : "ft0", "ft1", "ft3", "memory");
+  }
+
+  snrt_fpu_fence();
+  snrt_ssr_disable();
+
+  if (ccfg->cycle_end == 0)
+    ccfg->cycle_end = read_csr(mcycle);
+  if (ccfg->max_stmps)
+    ccfg->stmps[--ccfg->max_stmps] = read_csr(mcycle);
+
+  // Sort
+  for (int i = 0; i < data_size; i++) {
+    output[i].index = i;
+  }
+  shell_sort(output, data_size);
+
+  if (ccfg->max_stmps)
+    ccfg->stmps[--ccfg->max_stmps] = read_csr(mcycle);
+}
+
+void knn_1d(uint32_t K, uint32_t query_size, uint32_t data_size, double *query, double *data,
+            struct knn_aux *output, computeConfig_t *ccfg) {
+  uint32_t compute_id = snrt_cluster_compute_core_idx();
+  uint32_t compute_num = snrt_cluster_compute_core_num();
+
+  if (snrt_is_dm_core()) {
+    /** COPY **/
+
+  } else {
+    /** COMPUTE **/
+    // Each hart computes one sample
+    for (unsigned s = compute_id; s < query_size; s += compute_num) {
+      knn_seq(K, 1, data_size, &query[s], data, &output[data_size * s], ccfg);
+    }
+  }
+}
-- 
2.15.1

